{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../train')\n",
    "from helper import *\n",
    "%matplotlib inline\n",
    "\n",
    "#Wireless Parameters\n",
    "N_t = 64\n",
    "N_r = 16\n",
    "latent_dim = 65\n",
    "channel_model = 'A'\n",
    "\n",
    "length = int(N_t/4)\n",
    "breadth = int(N_r/4)\n",
    "\n",
    "G_test = torch.nn.Sequential(\n",
    "    torch.nn.Linear(latent_dim, 128*length*breadth),\n",
    "    torch.nn.ReLU(),\n",
    "    View([1,128,length,breadth]),\n",
    "    torch.nn.Upsample(scale_factor=2),\n",
    "    Conv2d(128,128,4,bias=False),\n",
    "    torch.nn.BatchNorm2d(128,momentum=0.8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Upsample(scale_factor=2),\n",
    "    Conv2d(128,128,4,bias=False),\n",
    "    torch.nn.BatchNorm2d(128,momentum=0.8),\n",
    "    torch.nn.ReLU(),\n",
    "    Conv2d(128,2,4,bias=False),\n",
    ")\n",
    "G_test = G_test.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "H_org = sio.loadmat(\"../../data/H_16x64_MIMO_CDL_%s_ULA_clean.mat\"%channel_model)\n",
    "H_ex = H_org['hest']\n",
    "H_extracted = np.transpose(copy.deepcopy(H_ex),(2,1,0))\n",
    "dft_basis = sio.loadmat(\"../../data/dft_basis.mat\")\n",
    "A_T = dft_basis['A1']/np.sqrt(N_t)\n",
    "A_R = dft_basis['A2']/np.sqrt(N_r)\n",
    "for i in range(H_ex.shape[2]):\n",
    "    H_extracted[i] = np.transpose(np.matmul(np.matmul(A_R.conj().T,H_extracted[i].T,dtype='complex64'),A_T))\n",
    "\n",
    "img_np_real = np.real(H_extracted)\n",
    "img_np_imag = np.imag(H_extracted)\n",
    "\n",
    "mu_real = np.mean(img_np_real,axis=0)\n",
    "mu_imag = np.mean(img_np_imag,axis=0)\n",
    "std_real = np.std(img_np_real,axis=0)\n",
    "std_imag = np.std(img_np_imag,axis=0)\n",
    "\n",
    "A_T_R = np.kron(A_T.conj(),A_R)\n",
    "A_T_R_real = dtype(np.real(A_T_R))\n",
    "A_T_R_imag = dtype(np.imag(A_T_R))\n",
    "\n",
    "H_org = sio.loadmat(\"../../data/H_16x64_MIMO_CDL_%s_ULA_test.mat\"%channel_model)\n",
    "H_ex = H_org['hest']\n",
    "H_extracted = np.transpose(copy.deepcopy(H_ex),(2,1,0))\n",
    "for i in range(H_ex.shape[2]):\n",
    "    H_extracted[i] = np.transpose(np.matmul(np.matmul(A_R.conj().T,H_extracted[i].T,dtype='complex64'),A_T))\n",
    "img_np_real = np.real(H_extracted)\n",
    "img_np_imag = np.imag(H_extracted)\n",
    "img_np_real = (img_np_real - mu_real)/std_real\n",
    "img_np_imag = (img_np_imag - mu_imag)/std_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_s = N_r\n",
    "N_rx_rf = N_r\n",
    "Nbit_t = 6\n",
    "Nbit_r = 2\n",
    "angles_t = np.linspace(0,2*np.pi,2**Nbit_t,endpoint=False)\n",
    "angles_r = np.linspace(0,2*np.pi,2**Nbit_r,endpoint=False)\n",
    "freq = 10\n",
    "model_vec = range(0,610,freq)\n",
    "\n",
    "def training_precoder(N_t,N_s):\n",
    "    angle_index = np.random.choice(len(angles_t),(N_t,N_s))\n",
    "    return (1/np.sqrt(N_t))*np.exp(1j*angles_t[angle_index])\n",
    "\n",
    "def training_combiner(N_r,N_rx_rf):\n",
    "    angle_index = np.random.choice(len(angles_r),(N_r,N_rx_rf))\n",
    "    W = (1/np.sqrt(N_r))*np.exp(1j*angles_r[angle_index])\n",
    "    return np.matrix(W).getH()\n",
    "\n",
    "ntest = 20              \n",
    "nrepeat = 5 #Different noise realizations\n",
    "SNR_vec = range(15,20,5)\n",
    "alpha = 0.4\n",
    "nmse_fedambgan = np.zeros((len(SNR_vec),len(model_vec)))\n",
    "ct = 0\n",
    "N_p = int(alpha*N_t)\n",
    "qpsk_constellation = (1/np.sqrt(2))*np.array([1+1j,1-1j,-1+1j,-1-1j])\n",
    "\n",
    "pilot_sequence_ind = np.random.randint(0,4,size=(N_s,N_p))\n",
    "symbols = qpsk_constellation[pilot_sequence_ind]\n",
    "precoder_training = training_precoder(N_t,N_s)\n",
    "W = training_combiner(N_r,N_rx_rf)\n",
    "A = np.kron(np.matmul(symbols.T,precoder_training.T),W)\n",
    "\n",
    "A_real = dtype(np.real(A))\n",
    "A_imag = dtype(np.imag(A))\n",
    "identity = np.identity(N_r)\n",
    "lambda_reg = 1e-3\n",
    "ct += 1\n",
    "for model in model_vec:\n",
    "    if model < 600:\n",
    "        G_test.load_state_dict(torch.load('../../results/pilot_gan/U_4/fedpilotgan/cache/checkpoints/n_d_5/global_G_state%d.pkl'%model)) \n",
    "    else:\n",
    "        G_test.load_state_dict(torch.load('../../results/pilot_gan/U_4/fedpilotgan/cache/checkpoints/n_d_5/global_G_state%d.pkl')) \n",
    "    G_test.eval()\n",
    "    for SNR in SNR_vec:\n",
    "        for i in range(nrepeat):\n",
    "            for ind in range(ntest):\n",
    "                vec_H_single = np.reshape(H_ex[:,:,ind].flatten('F'),[N_r*N_t,1])\n",
    "                signal = np.matmul(H_ex[:,:,ind],np.matmul(precoder_training,symbols))\n",
    "                E_s = np.multiply(signal,np.conj(signal))\n",
    "                noise_matrix = (1/np.sqrt(2))*(np.random.randn(N_r,N_p)+1j*np.random.randn(N_r,N_p))\n",
    "                vec_y = np.zeros((N_rx_rf*N_p,1,1),dtype='complex64')\n",
    "                std_dev = (1/(10**(SNR/20)))*np.sqrt(E_s)\n",
    "                rx_signal = signal + np.multiply(std_dev,noise_matrix)\n",
    "                rx_signal = np.matmul(W,rx_signal)\n",
    "                vec_y[:,0,0] = rx_signal.flatten('F') \n",
    "                vec_y_real = dtype(np.real(vec_y[:,:,0]))\n",
    "                vec_y_imag = dtype(np.imag(vec_y[:,:,0]))\n",
    "                def gen_output(x):\n",
    "                    pred = G_test(x)\n",
    "                    pred[0,0,:,:] = dtype(std_real)*pred[0,0,:,:] + dtype(mu_real)\n",
    "                    pred[0,1,:,:] = dtype(std_imag)*pred[0,1,:,:] + dtype(mu_imag)\n",
    "                    pred_real = torch.mm(A_T_R_real,pred[0,0,:,:].view(N_t*N_r,-1)) - torch.mm(A_T_R_imag,pred[0,1,:,:].view(N_t*N_r,-1))\n",
    "                    pred_imag = torch.mm(A_T_R_real,pred[0,1,:,:].view(N_t*N_r,-1)) + torch.mm(A_T_R_imag,pred[0,0,:,:].view(N_t*N_r,-1))\n",
    "                    diff_real = vec_y_real - torch.mm(A_real,pred_real) + torch.mm(A_imag,pred_imag)\n",
    "                    diff_imag = vec_y_imag - torch.mm(A_real,pred_imag) - torch.mm(A_imag,pred_real)\n",
    "                    diff = torch.norm(diff_real)**2 + torch.norm(diff_imag)**2\n",
    "                    return diff + lambda_reg*torch.norm(x)**2\n",
    "                x = Variable(torch.randn(1, latent_dim)).type(dtype)\n",
    "                x.requires_grad = True\n",
    "                learning_rate = 1e-1\n",
    "                optimizer = torch.optim.Adam([x], lr=learning_rate)\n",
    "                for a in range(100): \n",
    "                    optimizer.zero_grad()\n",
    "                    loss = gen_output(x)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                gen_imgs = G_test(x).data.cpu().numpy()\n",
    "                gen_imgs[0,0,:,:] = std_real*gen_imgs[0,0,:,:] + mu_real\n",
    "                gen_imgs[0,1,:,:] = std_imag*gen_imgs[0,1,:,:] + mu_imag\n",
    "                gen_imgs_complex = gen_imgs[0,0,:,:] + 1j*gen_imgs[0,1,:,:]\n",
    "                gen_imgs_complex = np.matmul(A_T_R,np.reshape(gen_imgs_complex,[N_t*N_r,1]))\n",
    "                nmse_fedambgan[ct-1,int((model-model_vec[0])/freq)] = nmse_fedambgan[ct-1,int((model-model_vec[0])/freq)] + (np.linalg.norm(gen_imgs_complex - vec_H_single)/np.linalg.norm(vec_H_single))**2\n",
    "                print((np.linalg.norm(gen_imgs_complex - vec_H_single)/np.linalg.norm(vec_H_single))**2)\n",
    "nmse_fedambgan = nmse_fedambgan/(ntest*nrepeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=4,window='hanning'):\n",
    "    if window_len<3:\n",
    "        return x\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y[(int(window_len/2)-1):-int(window_len/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.legend_handler import HandlerLine2D, HandlerTuple\n",
    "model_vec_2 = range(0,610,20)\n",
    "p1, = plt.plot(model_vec_2,smooth(10*np.log10(nmse_CDL_A_ld_65).T[np.arange(0,61,2),0],6),'o-')\n",
    "p2, = plt.plot(model_vec_2,smooth(10*np.log10(nmse_CDL_A_ld_65_n_d_20).T[np.arange(0,61,2),0],6),'v-')\n",
    "p3, = plt.plot(model_vec_2,smooth(10*np.log10(nmse_fedambgan).T[np.arange(0,61,2),0],6),'o-')\n",
    "p4, = plt.plot(model_vec_2,smooth(10*np.log10(nmse_fedambgan_n_d_20).T[np.arange(0,61,2),0],6),'v-')\n",
    "plt.legend([(p2, p4), (p1, p3)], [r'$n_d = 20$',r'$n_d = 5$'], numpoints=1,\n",
    "               handler_map={tuple: HandlerTuple(ndivide=None)},loc = 'upper right')\n",
    "plt.grid(ls=':')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('NMSE(in dB)')\n",
    "plt.xlim([-10,610])\n",
    "plt.savefig('../../results/FedGAN.pdf',dpi=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
